{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install lughaatNLP"
      ],
      "metadata": {
        "id": "TNHr-hPm2gwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#useable code best approach\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk import ConditionalFreqDist, bigrams, trigrams\n",
        "from LughaatNLP import LughaatNLP\n",
        "import random\n",
        "\n",
        "# Initialize LughaatNLP for text processing\n",
        "urdu_text_processing = LughaatNLP()\n",
        "\n",
        "# Load the Urdu text data\n",
        "file_path = 'urdu_stories.csv'  # Update with your file path\n",
        "urdu_stories_df = pd.read_csv(file_path, header=None)\n",
        "urdu_stories_df.columns = ['story_name', 'story_content']\n",
        "\n",
        "# Tokenize the stories, normalize the text, and extract starting words\n",
        "def tokenize_and_extract_starting_words(content):\n",
        "    normalized_text = urdu_text_processing.normalize(content)  # Normalize the content\n",
        "    sentences = re.split(r'[؟.-]', normalized_text)\n",
        "\n",
        "    starting_words = []\n",
        "    tokens = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if sentence.strip():  # Avoid empty sentences\n",
        "            sentence_tokens = urdu_text_processing.urdu_tokenize(sentence)\n",
        "            if sentence_tokens:  # Check if there are tokens\n",
        "                starting_words.append(sentence_tokens[0])  # Store the first word of the sentence\n",
        "                tokens.extend(sentence_tokens)  # Collect all tokens for bigrams/trigrams\n",
        "\n",
        "    return tokens, starting_words\n",
        "\n",
        "# Apply tokenization and extract starting words\n",
        "urdu_stories_df['tokens'], urdu_stories_df['starting_words'] = zip(*urdu_stories_df['story_content'].apply(tokenize_and_extract_starting_words))\n",
        "\n",
        "# Generate bigrams and trigrams from tokens\n",
        "urdu_stories_df['bigrams'] = urdu_stories_df['tokens'].apply(lambda tokens: list(bigrams(tokens)))\n",
        "urdu_stories_df['trigrams'] = urdu_stories_df['tokens'].apply(lambda tokens: list(trigrams(tokens)))\n",
        "\n",
        "# Create Conditional Frequency Distribution for bigrams and trigrams with Laplace smoothing\n",
        "bigrams_list = [bigram for story_bigrams in urdu_stories_df['bigrams'] for bigram in story_bigrams]\n",
        "trigrams_list = [trigram for story_trigrams in urdu_stories_df['trigrams'] for trigram in story_trigrams]\n",
        "\n",
        "cfd_bigrams = ConditionalFreqDist(bigrams_list)\n",
        "cfd_trigrams = ConditionalFreqDist((w1 + ' ' + w2, w3) for w1, w2, w3 in trigrams_list)\n",
        "\n",
        "# Laplace smoothing function for bigrams\n",
        "def laplace_smoothing(cfd, word1, word2, vocab_size):\n",
        "    return (cfd[word1][word2] + 1) / (cfd[word1].N() + vocab_size)\n",
        "\n",
        "# Laplace smoothing function for trigrams\n",
        "def laplace_smoothing_trigram(cfd, w1, w2, w3, vocab_size):\n",
        "    return (cfd[(w1, w2)][w3] + 1) / (cfd[(w1, w2)].N() + vocab_size)\n",
        "\n",
        "# Collect all unique starting words from all stories into a single pool\n",
        "all_starting_words = list(set(word for sublist in urdu_stories_df['starting_words'] for word in sublist))\n",
        "vocab_size = len(set(urdu_stories_df['tokens'].sum()))  # Total unique tokens for smoothing\n",
        "\n",
        "# Define a set of valid end words for sentences\n",
        "valid_end_words = {'آخر', 'پہلے', 'ختم', 'تک', 'بات', 'یہ', 'کیا', 'ہے', 'تھی', 'کرنا', 'گا', 'جاتا', 'پر', 'ہوں'}  # Add more words as needed\n",
        "\n",
        "# Function to generate sentences using trigrams with improved coherence\n",
        "def generate_sentence(cfd_model_bigram, cfd_model_trigram, start_word, length=10, used_words=set()):\n",
        "    sentence = [start_word]\n",
        "\n",
        "    for _ in range(length - 1):\n",
        "        # Attempt to use trigram model\n",
        "        if len(sentence) >= 2:  # Ensure we have at least two words for the trigram\n",
        "            bigram_key = ' '.join(sentence[-2:])  # Get the last two words for the trigram\n",
        "            next_word_probabilities = {word: laplace_smoothing_trigram(cfd_model_trigram, sentence[-2], sentence[-1], word, vocab_size)\n",
        "                                        for word in cfd_model_trigram[bigram_key]}\n",
        "            next_word = max(next_word_probabilities, key=next_word_probabilities.get)  # Get the most probable next word\n",
        "\n",
        "            if next_word not in used_words:  # Check if the word has already been used\n",
        "                sentence.append(next_word)\n",
        "                used_words.add(next_word)  # Add to used words\n",
        "\n",
        "                # Check if the next word is a valid end word\n",
        "                if next_word in valid_end_words:\n",
        "                    break  # End sentence if a valid end word is found\n",
        "                continue  # Move to the next iteration\n",
        "\n",
        "        # Fallback to bigram model\n",
        "        if len(sentence) >= 1:\n",
        "            last_word = sentence[-1]  # Get the last word for the bigram\n",
        "            next_word_probabilities = {word: laplace_smoothing(cfd_model_bigram, last_word, word, vocab_size)\n",
        "                                        for word in cfd_model_bigram[last_word]}\n",
        "            next_word = max(next_word_probabilities, key=next_word_probabilities.get)  # Get the most probable next word\n",
        "\n",
        "            if next_word not in used_words:  # Check if the word has already been used\n",
        "                sentence.append(next_word)\n",
        "                used_words.add(next_word)  # Add to used words\n",
        "\n",
        "                # Check if the next word is a valid end word\n",
        "                if next_word in valid_end_words:\n",
        "                    break  # End sentence if a valid end word is found\n",
        "            else:\n",
        "                # Find the next highest probable word\n",
        "                next_candidates = [word for word in cfd_model_bigram[last_word].keys() if word not in used_words]\n",
        "                if next_candidates:\n",
        "                    next_word = random.choice(next_candidates)  # Select a random candidate from available options\n",
        "                    sentence.append(next_word)\n",
        "                    used_words.add(next_word)  # Add to used words\n",
        "\n",
        "                    # Check if the next word is a valid end word\n",
        "                    if next_word in valid_end_words:\n",
        "                        break  # End sentence if a valid end word is found\n",
        "                else:\n",
        "                    break  # Stop if no next word is found\n",
        "\n",
        "    return ' '.join(sentence)\n",
        "\n",
        "# Function to generate paragraphs using the combined pool of starting words, maintaining coherence\n",
        "def generate_paragraphs(num_paragraphs=3):\n",
        "    for _ in range(num_paragraphs):\n",
        "        paragraph = []\n",
        "        used_words = set()  # Track used words in the paragraph\n",
        "\n",
        "        for _ in range(random.randint(5, 19)):  # Random number of sentences between 5 and 19\n",
        "            if paragraph:  # If there are already sentences in the paragraph\n",
        "                last_sentence = paragraph[-1]\n",
        "                last_word = last_sentence.split()[-1]  # Use the last word of the previous sentence\n",
        "                start_word = get_starting_word_based_on_last(last_word, cfd_bigrams)\n",
        "            else:\n",
        "                start_word = random.choice(all_starting_words)  # Select a random starting word\n",
        "\n",
        "            # If no valid starting word is found, choose a random one from all starting words\n",
        "            if not start_word:\n",
        "                start_word = random.choice(all_starting_words)\n",
        "\n",
        "            # Generate the sentence using both bigram and trigram models\n",
        "            sentence = generate_sentence(cfd_bigrams, cfd_trigrams, start_word, length=random.randint(5, 19), used_words=used_words)\n",
        "            paragraph.append(sentence)\n",
        "\n",
        "        # Print the generated paragraph\n",
        "        print('\\n'.join(paragraph))\n",
        "        print(\"\\n\")  # Print an empty line after each paragraph\n",
        "\n",
        "# Function to get potential starting words based on the last word using bigram model\n",
        "def get_starting_word_based_on_last(last_word, cfd_model_bigram):\n",
        "    possible_starting_words = []\n",
        "\n",
        "    # Iterate through the keys in cfd_model_bigram to find matches\n",
        "    for (w1, w2) in cfd_model_bigram.items():\n",
        "        if w1 == last_word:\n",
        "            possible_starting_words.extend(w2.keys())  # Extend with the keys (w2) for each matching w1\n",
        "\n",
        "    return random.choice(possible_starting_words) if possible_starting_words else None\n",
        "\n",
        "# Run the paragraph generation\n",
        "generate_paragraphs()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3bRfw8nX37O",
        "outputId": "106f47c7-b5c0-4c6a-92f4-3613d9be52d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "جنگ میں کام کرنے کے بعد وہ پھر سے\n",
            "لفنگوں، والی نہ تھی\n",
            "ھوئی ۔ کیس چلا بالاخر یہ\n",
            "اپیل اور رہائی قدرے آسان ہوتی ہے\n",
            "گرلز کالج پہنچ گئے ہی نہیں سوچتے کہ چچا جان نے اس کی طرف دیکھا\n",
            "\n",
            "\n",
            "پھر اس نے کہا ۔ میں حقہ گڑگڑاتا\n",
            "رہا تھا دانیال بولتے ہوئے دراز قد شخص کو دیکھ کر وہ ایک بار پھر وکیلوں کی فیسیں کب\n",
            "کون ہے\n",
            "جین جلدی سے تھمے ہی نہیں،\n",
            "پاکستان چلی گئیں تمہیں پہلی محبت چل رہی تھی\n",
            "مہتاب علی صاحب کچھ الجھے رہو گے تین چار دن\n",
            "شایان تم اب بھی نہیں بھولے بھالے اور اکلوتے صاحبزادے کے ساتھ لے پکڑ سو روپے\n",
            "تو بتاؤ، اگر تجھ پرنہیں ڈالا کرتے تھے رمجو اٹھ سکتی ہوں\n",
            "عادل نمائندے دونوں وہیں کھڑے وکیل سرکار ظہیر الدین بیمار پڑ گئے اپ ضرور لیں\n",
            "پلیز مجھے جانے دو خاندان تھا، مختار احمد ٹھیک ہے، مرچیں لگ رہا ذہن معمولی بات\n",
            "شدو مد نظر تھیں سونو کہاں\n",
            "چوکتیں کیونکہ فصیح جب گائوں جانا ہم موت مرنے دیں شاید اسی لئے ٹریفک\n",
            "سے جمیل کا تصور جاناں کئے بغیر خون اگلتا\n",
            "ڈھیر ساری باتیں سن لیجئے، بھگوان آپ تشریف لارہے ہیں امریکہ پڑھنے\n",
            "لگتی، جیسے اسے اپنے گھر اجڑ گیا رحیم میک کلس کھانے بیٹھا کسی عیب موجود نہ چلے،\n",
            "ذرا سی ٹوپی رکھ دیا ایسا کیس ہوتا کہ ٹیکسی والا اچھا انسان اپنا بچپن محرومیوں بھرے حالات\n",
            "سنبھلنے لگی ان دنوں بھائی، والدہ قریبی چارپائی پر\n",
            "\n",
            "\n",
            "بھرے لہجے میں کہا ۔\n",
            "بدشکل سے شادی کی تاریخ طے کر دیا و\n",
            "خوف زدہ ہوگئی ٭ واپسی پر\n",
            "روحانی برکات کے دروازے جتنی\n",
            "ضرورت نہیں ہے\n",
            "طبیعت خراب ہو گئی امینہ بیگم نے شکیلہ\n",
            "کا نام نصیر باجوہ آگیا ہوں، چھوٹا ہونا میرے لئے ایک بڑا سا گھر تھا خانیہ حیرت والی\n",
            "بدبو پھیلی ہوئی تھی\n",
            "غیر معمولی بات\n",
            "آہستہ آہستہ اس اجلاس برخاست کردیا جائے گا\n",
            "لاتعداد نشانات تھے اور ان دیکھے، انجانے سپنے جھانک رہے انہوں اسے واقعی سچ\n",
            "بولا تمہاری لڑکی کو دکھاتا ہوں\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}